{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13e1c89",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Reference Notebook\n",
    "\n",
    "This notebook serves as a comprehensive reference for key concepts in Machine Learning. You can refer to this notebook when working on ML projects or revising concepts.\n",
    "\n",
    "## 1. **Linear Algebra**\n",
    "\n",
    "### Vectors and Matrices:\n",
    "- **Vectors**: A one-dimensional array of numbers.\n",
    "- **Matrices**: A two-dimensional array of numbers.\n",
    "\n",
    "#### Common Operations:\n",
    "- **Dot Product**: The product of two vectors.\n",
    "- **Matrix Multiplication**: Multiplying matrices together.\n",
    "- **Transpose**: Flipping a matrix over its diagonal.\n",
    "\n",
    "#### Python Libraries:\n",
    "- `numpy` for vector and matrix operations.\n",
    "```python\n",
    "import numpy as np\n",
    "# Example: Create a matrix\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "```\n",
    "\n",
    "## 2. **Probability and Statistics**\n",
    "\n",
    "### Basic Concepts:\n",
    "- **Probability Distributions**: Describes the likelihood of outcomes.\n",
    "- **Expectation**: The mean of a random variable.\n",
    "- **Variance**: The spread of a distribution.\n",
    "\n",
    "#### Common Distributions:\n",
    "- **Normal Distribution**: Bell curve, used widely in statistics.\n",
    "- **Bernoulli Distribution**: Models binary outcomes (0 or 1).\n",
    "\n",
    "#### Python Libraries:\n",
    "- `scipy.stats` for probability distributions.\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "# Example: Calculate probability for normal distribution\n",
    "norm.cdf(1.96)\n",
    "```\n",
    "\n",
    "## 3. **Supervised Learning**\n",
    "\n",
    "### Linear Regression:\n",
    "- Predict continuous values.\n",
    "- **Equation**: \\(y = w_0 + w_1x_1 + \\dots + w_nx_n\\).\n",
    "- Minimize the **mean squared error** (MSE).\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Example: Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### Logistic Regression:\n",
    "- Used for binary classification.\n",
    "- **Sigmoid function**: Converts output to a probability between 0 and 1.\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Example: Fit a logistic regression model\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### Decision Trees and Random Forests:\n",
    "- **Decision Tree**: Splits data into subsets based on feature values.\n",
    "- **Random Forest**: Ensemble of decision trees to improve performance.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Example: Fit a random forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "## 4. **Unsupervised Learning**\n",
    "\n",
    "### Clustering:\n",
    "- Group data points into clusters.\n",
    "\n",
    "#### K-Means:\n",
    "- Iteratively assigns data points to clusters and updates centroids.\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "# Example: Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "```\n",
    "\n",
    "### Dimensionality Reduction:\n",
    "- Reduces the number of features in the dataset.\n",
    "\n",
    "#### Principal Component Analysis (PCA):\n",
    "- Projects data onto lower-dimensional space while preserving variance.\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "# Example: Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "## 5. **Evaluation Metrics**\n",
    "\n",
    "### Classification Metrics:\n",
    "- **Accuracy**: Proportion of correct predictions.\n",
    "- **Precision**: \\( \f",
    "rac{TP}{TP + FP} \\).\n",
    "- **Recall**: \\( \f",
    "rac{TP}{TP + FN} \\).\n",
    "- **F1 Score**: Harmonic mean of precision and recall.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Example: Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "## 6. **Deep Learning**\n",
    "\n",
    "### Neural Networks:\n",
    "- Composed of layers of neurons.\n",
    "- Each neuron applies a weighted sum and an activation function.\n",
    "\n",
    "### Activation Functions:\n",
    "- **ReLU**: \\(f(x) = max(0, x)\\).\n",
    "- **Sigmoid**: \\(f(x) = \f",
    "rac{1}{1 + e^{-x}}\\).\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Example: Create a neural network with Keras\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "## 7. **Optimization**\n",
    "\n",
    "### Gradient Descent:\n",
    "- Update model weights to minimize the loss function.\n",
    "- Variants include **SGD**, **Adam**, and **RMSprop**.\n",
    "\n",
    "```python\n",
    "# Example: Compile a neural network model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "## 8. **Model Evaluation**\n",
    "\n",
    "### Cross-Validation:\n",
    "- Evaluate model performance on different subsets of the data.\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Example: Perform cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "```\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "- Use **Grid Search** or **Random Search** to find optimal model parameters.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Example: Perform grid search for hyperparameter tuning\n",
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "## 9. **Real-World Applications**\n",
    "\n",
    "### Natural Language Processing (NLP):\n",
    "- Tasks: Text classification, sentiment analysis.\n",
    "- Tools: Bag-of-Words, TF-IDF, Word2Vec, Transformers.\n",
    "\n",
    "### Computer Vision:\n",
    "- Tasks: Image classification, object detection, segmentation.\n",
    "- Tools: CNNs, ResNet, YOLO.\n",
    "\n",
    "### Time Series Forecasting:\n",
    "- Tasks: Stock price prediction, demand forecasting.\n",
    "- Tools: ARIMA, LSTM.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook provides references to key concepts in Machine Learning, along with code snippets for practical implementation using Python and popular ML libraries.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
